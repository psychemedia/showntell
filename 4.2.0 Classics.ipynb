{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# Classics\n\nSome tools to support classics related subject matter, such as retrieving classical texts and searching throuhg them, analysing grammar, inflectng words (declensions, conjugations).\n\nThe intention, as with the other notebooks in this collection, is to explore ways in which we might create educational resources that are \"reproducible with modification\" through making available the means of production of various analyses, diagrams, etc along with the produced resource.\n\nA secondary benefit is that by automating the generation of particular assets or examples, it becomes easier for authors to make use of them, which may open up new teaching lines. A tertiary benefit is that learners may use the same production methods to allow them to explore the topics themselves. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## `cltk`\n\n`cltk`, the [ Classical Language Toolkit](https://github.com/cltk/cltk), is a natural language processing (NLP) package designed for use with the languages of Ancient, Classical, and Medieval Eurasia (esp. Greek and Latin). I assume it is based on `nltk`.\n\nA selection of tutorial notebooks can be found at [cltk/tutorials](https://github.com/cltk/tutorials).\n\n`cltk` provides access to a variety of classical texts in a variety of languages, and as such provides a way for learners to access such texts themselves, *if* we can find a way of accessing a reliable index to them, or search through metadata provided for them.\n\nThe natural language processing tools in the package make it easy to search texts, as well as analyse them in some languages.\n\nThere are also language specific tools, such as a declension generator in Latin, that might be useful for helping check declensions and conjugations, or display particular person/tense combinations for a particular word.\n\nOpenLearn units to explore:\n\n- [Discovering Acient Greek and Latin](http://www.open.edu/openlearn/history-the-arts/discovering-ancient-greek-and-latin/content-section-0?active-tab=description-tab)\n- [Getting started on classical Latin](http://www.open.edu/openlearn/history-the-arts/getting-started-on-classical-latin/content-section-0?active-tab=description-tab)\n- [Continuing classical Latin](http://www.open.edu/openlearn/history-the-arts/history/classical-studies/continuing-classical-latin/content-section-0?active-tab=description-tab)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%capture\ntry:\n    import cltk\nexcept:\n    !pip install --upgrade matplotlib\n    !pip install --upgrade --no-cache-dir git+https://github.com/cltk/cltk.git",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#CLTK is the core analysis package in a family of packages that act as data sources\n#  for a wide range of classical languages.\n# The external packages include language models and corpus collections\n#stores all data in the local directory cltk_data,\n#CLTK create a data directory in a user’s root directory upon first initialization \n#of the CorpusImporter() class into which data collections are downloaded.\nfrom cltk.corpus.utils.importer import CorpusImporter\n\nCorpusImporter('greek').list_corpora ",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "['greek_software_tlgu',\n 'greek_text_perseus',\n 'phi7',\n 'tlg',\n 'greek_proper_names_cltk',\n 'greek_models_cltk',\n 'greek_treebank_perseus',\n 'greek_lexica_perseus',\n 'greek_training_set_sentence_cltk',\n 'greek_word2vec_cltk',\n 'greek_text_lacus_curtius',\n 'greek_text_first1kgreek']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "CorpusImporter('latin').list_corpora",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "['latin_text_perseus',\n 'latin_treebank_perseus',\n 'latin_text_latin_library',\n 'phi5',\n 'phi7',\n 'latin_proper_names_cltk',\n 'latin_models_cltk',\n 'latin_pos_lemmata_cltk',\n 'latin_treebank_index_thomisticus',\n 'latin_lexica_perseus',\n 'latin_training_set_sentence_cltk',\n 'latin_word2vec_cltk',\n 'latin_text_antique_digiliblt',\n 'latin_text_corpus_grammaticorum_latinorum',\n 'latin_text_poeti_ditalia']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "CorpusImporter('tibetan').list_corpora\n#old_english, hebrew, arabic, sanskrit, begali, chinese, coptic, hindi, old_norse,\n#punjabi, tibetan, latin, greek",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "['tibetan_pos_tdc', 'tibetan_lexica_tdc']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from cltk.corpus.utils.importer import CorpusImporter\n\n#on first run, this imports to ~/cltk_data/latin/latin_text_latin_library\nCorpusImporter('latin').import_corpus('latin_text_latin_library')\n\n#We also need access to tokenizers/punkt/PY3/english.pickle\n# to extract sentences, tokens etc\nimport nltk\nnltk.download('punkt')",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[nltk_data] Downloading package punkt to /home/nbuser/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!ls ~/cltk_data/latin/text/latin_text_latin_library/vergil",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "aen10.txt  aen2.txt  aen6.txt  ec10.txt  ec4.txt  ec8.txt   geo3.txt\r\naen11.txt  aen3.txt  aen7.txt  ec1.txt\t ec5.txt  ec9.txt   geo4.txt\r\naen12.txt  aen4.txt  aen8.txt  ec2.txt\t ec6.txt  geo1.txt\r\naen1.txt   aen5.txt  aen9.txt  ec3.txt\t ec7.txt  geo2.txt\r\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can now work with this corpus (even though we don't really know what's in it? *Is there an index somewhere? How do folk find what file they want, or how do they even know what's available? Original website form which library files are taken is presumably [The Latin Library](http://thelatinlibrary.com/)?)."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from cltk.corpus import latin\nfrom os.path import expanduser\n\n#We need to get tthe absolute path to the installed files\nc= latin.PlaintextCorpusReader(expanduser('~/cltk_data/latin/text/latin_text_latin_library'),\n                               '.*\\.txt')\n",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Access the raw text\nprint(c.raw()[1015:1100])",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\n\n \n TABULA III \n \n\n \nAeris confessi rebusque iure iudicatis\nXXX dies iusti sunto. \n\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Extract individual sentences\nc.sents()[10]",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "['Proletario', 'iam', 'civi', 'quis', 'volet', 'vindex', 'esto', '.']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Load in a single file from the corpus\n#I'm not sure how to get the path to the specific file without the leading .*/?\n\naen_c= latin.PlaintextCorpusReader(expanduser('~/cltk_data/latin/text/latin_text_latin_library'),\n                               '.*/aen.*\\.txt')\nlen(aen_c.sents())\n\n#if we load in '.*/aen.*\\.txt' what order are then in?\n#Does sort give aen11.txt before aen1.txt?\naen_c.sents()[10]==c.sents()[10]\n",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "False"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Get a single file\naen1= latin.PlaintextCorpusReader(expanduser('~/cltk_data/latin/text/latin_text_latin_library'),\n                               '.*/aen1.txt')\nprint(aen1.raw()[1000:1200])\n",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Tyrias olim quae verteret arces;    20 \nhinc populum late regem belloque superbum \nventurum excidio Libyae: sic volvere Parcas. \nId metuens, veterisque memor Saturnia belli, \nprima quod ad Troiam pro \n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#From the repo it looks like there is one local corpus\n#https://github.com/cltk/cltk/blob/master/cltk/corpus/latin\n#with an index:\n#https://github.com/cltk/cltk/blob/master/cltk/corpus/latin/phi5_index.py\n\nimport cltk.corpus.latin.phi5_index as phi\n#phi.PHI5_INDEX\n#phi.PHI5_WORKS_INDEX",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "{k:v for k,v in phi.PHI5_WORKS_INDEX.items() if 'Catullus' in v['name']}",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "{'LAT0472': {'name': 'Gaius Valerius Catullus', 'works': ['001', '002']}}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#borked?\n#CorpusImporter('latin').import_corpus('phi5')",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Looking at the texts"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#https://github.com/cltk/tutorials/blob/master/9%20Lexical%20Dispersion%20Plot.ipynb\nimport cltk\nfrom nltk.tokenize import word_tokenize \nfrom cltk.tokenize.word import WordTokenizer\nimport matplotlib.pyplot as plt",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def dispersionPlot(text, words, lang):\n    languages = [\"en\",\"bn\",\"hi\",\"la\",\"sa\"]\n    \"\"\"\n    en:English\n    bn:Bengali\n    hi:Hindi\n    la:Latin\n    sa:Sanskrit\n    \"\"\"\n    if lang in languages:\n        if lang in [\"en\",\"la\"]:\n            tokens = word_tokenize(text.lower())\n            for i in range(0,len(words)):\n                words[i] = words[i].lower()\n        if lang in [\"bn\",\"hi\",\"sa\"]:\n            tokens= i_word(text)\n    \n    # Locating the matches of the words in the text.    \n        x_length = len(tokens)\n        y_length = len(words)\n        x_list = []\n        y_list = []\n        for i in range(0,x_length):\n            for j in range(0,y_length):\n                if tokens[i]==words[j]:\n                    x_list.append(i+1)\n                    y_list.append(j)\n    \n    #Creation of Dispersion Plot with Matplotlib's pyplot.         \n        plt.plot(x_list, y_list, \"b|\", scalex=.1)\n        plt.yticks(list(range(len(words))), words, color=\"b\")\n        plt.ylim(-1, len(words))\n        plt.xlabel(\"Lexical Distribution\")\n        plt.show()\n            \n    else:\n        print(\"Language not presently covered by CLTK or wrong language code\")",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Sometimes it can be useful to look at the distribution of a particular word, or set of words, through a text. A *dispersion plot* reveals this distribution."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "words = [\"Troiam\",\"Libyae\"]\ndispersionPlot(aen1.raw(), words, \"la\")",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAEBBJREFUeJzt3XuMZnV9x/H3F3a5KMjFXaiwwgCaKLEUYUCqIOINtUYgLhGlRdSWVG0tVdJANS6YSKSJ12CCBA22bKstYFgxja4riqGBZZbbroiw3FKLdRWvS0HX3W//OL9hnx2+s7OzM7PPPDvvV/Jkzvmdy3zPbzLP5zmX55zITCRJGmuXfhcgSZqdDAhJUsmAkCSVDAhJUsmAkCSVDAhJUsmAkCSVDAhJUsmAkCSV5vW7gKlYsGBBDg0N9bsMSRooq1at+nlmLpxovoEOiKGhIUZGRvpdhiQNlIh4dFvm8xCTJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKk0qYCIYH37eVAE17bhcyO4fCaKkyT1z3btQWTyWCaLp7uYHenii/tdweCYjX01G2saaxBqHM8g1z6oJtPnO+rvE5m57TMH6zPZK4Ih4MZMXhLBucAZwD7AwcA1mVwSwceAX2Tymbbsx4F1wBeBG4D9gPnARzK5oc3z58AHgN2A24D3ZbJxvHqGh4dzZGRkkpv89LYwiU2f02ZjX83GmsYahBrHM8i1D6rJ9PlU/z4RsSozhyeab7rOQRwPvBU4CjgzgmHgS8A5XTHsApwFXAM8BZyRyTHAKcAnI4gIXgy8DXhFJkcDG4Gzp6k+SdIkzZum9SzP5HGACK4HTszkMxE8HsFLgQOBOzN5PIL5wKURvBLYRLfXcSDwGuBY4PYIAPak2+PYQkScB5wHcMghh0xT+ZKksaYrIMbu7IyOXwWcC/wR3R4FdHsFC4FjM9kQwSPAHkAAX87koq3+oswrgSuhO8Q0HcVLkp5pug4xvS6C/SPYEzgduKW1fw14A3Ac8M3Wtg+wroXDKcChrX0FsDiCAwDa+g5FktQX07UHsRK4DlhEd5J6BCCT30dwE/CrnpPNS4GvR7AaGAHua/PeG8FHgG+1cxYbgPcDj05TjVtYsmQm1rpzmo19NRtrGmsQahzPINc+qCbT5zvq7zOpq5gmvfLujf4O4MxMHpju9U/lKiZJmqt29FVMRQEcCawFVsxEOEiSZtZ0HWJ6hkzuBQ6fqfVLkmaW92KSJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSyYCQJJUMCElSaasBEcG+EbxvsiuN4L+2v6Qd5+KL+12BJM1eE+1B7AvPDIgI5m1toUxePpWidpRLLul3BZI0e00UEJ8Ajojgrghuj+D7ESwD7gWI4IMRrGmv80cXimB9+7lXBCsiuCOC1RGc1tqHIrgvgqsjuD+CpRG8NoJbInggguNnaHslSdtoq3sCwIXASzI5OoJXAd9o4w9HcCzwLuBlQAC3RfC9TO7sWf4p4IxMfhPBAuDWFjAALwDOBN4N3A68AzgReAvwj8DpVUERcR5wHsAhhxwy2e2VJG2jyZ6kXpnJw234ROBrmTyRyXrgeuCkMfMHcGkE9wDfBg4GDmzTHs5kdSabgB8AKzJJYDUwNF4BmXllZg5n5vDChQsnWb4kaVtNtAcx1hOTnP9sYCFwbCYbIngE2KNN+13PfJt6xjdtR12SpGk20R7Eb4G9x5n2feD0CJ4VwbOBM1pbr32AdS0cTgEOnVK102zJkn5XIEmz10RXIz3eThyvAZ4Eftoz7Y4IrgZWtqarxpx/AFgKfD2C1cAIcN+0VT4NvMxVksYXmdnvGrbb8PBwjoyM9LsMSRooEbEqM4cnms9vUkuSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSgaEJKlkQEiSSpGZ/a5hu0XEz4BHgQXAz/tczmxif2zJ/tiS/bHZXO2LQzNz4UQzDXRAjIqIkcwc7ncds4X9sSX7Y0v2x2b2xdZ5iEmSVDIgJEmlnSUgrux3AbOM/bEl+2NL9sdm9sVW7BTnICRJ029n2YOQJE2zgQ+IiHhDRPwoItZGxIX9rmemRMSXImJdRKzpads/IpZHxAPt536tPSLic61P7omIY3qWeWeb/4GIeGc/tmWqIuL5EXFTRNwbET+IiL9r7XO1P/aIiJURcXfrj0ta+2ERcVvb7q9GxG6tffc2vrZNH+pZ10Wt/UcRcWp/tmjqImLXiLgzIm5s43O2L6YkMwf2BewKPAgcDuwG3A0c2e+6ZmhbXwkcA6zpafsn4MI2fCFwWRt+E/CfQAAnALe19v2Bh9rP/drwfv3etu3oi+cBx7ThvYH7gSPncH8EsFcbng/c1rbz34GzWvsVwHvb8PuAK9rwWcBX2/CR7X9od+Cw9r+1a7+3bzv75IPAvwI3tvE52xdTeQ36HsTxwNrMfCgzfw98BTitzzXNiMy8GfjFmObTgC+34S8Dp/e0/3N2bgX2jYjnAacCyzPzF5n5S2A58IaZr356ZeZPMvOONvxb4IfAwczd/sjMXN9G57dXAq8Grm3tY/tjtJ+uBV4TEdHav5KZv8vMh4G1dP9jAyUiFgF/BlzVxoM52hdTNegBcTDw3z3jP25tc8WBmfmTNvy/wIFteLx+2en6qx0SeCndp+Y52x/tkMpdwDq6oHsQ+FVm/qHN0rttT293m/5r4LnsPP3xGeAfgE1t/LnM3b6YkkEPCDXZ7RfPqUvSImIv4Drg/Mz8Te+0udYfmbkxM48GFtF90n1Rn0vqi4h4M7AuM1f1u5adwaAHxP8Az+8ZX9Ta5oqftkMltJ/rWvt4/bLT9FdEzKcLh6WZeX1rnrP9MSozfwXcBPwp3aG0eW1S77Y9vd1t+j7A4+wc/fEK4C0R8QjdIedXA59lbvbFlA16QNwOvLBdobAb3UmmZX2uaUdaBoxeefNO4Iae9nPa1TsnAL9uh16+Cbw+IvZrV/i8vrUNlHaM+IvADzPzUz2T5mp/LIyIfdvwnsDr6M7L3AQsbrON7Y/RfloMfKftcS0DzmpX9hwGvBBYuWO2Ynpk5kWZuSgzh+jeD76TmWczB/tiWvT7LPlUX3RXqNxPd8z1w/2uZwa389+AnwAb6I6HvofuWOkK4AHg28D+bd4APt/6ZDUw3LOed9OdcFsLvKvf27WdfXEi3eGje4C72utNc7g/jgLubP2xBvhoaz+c7k1tLfAfwO6tfY82vrZNP7xnXR9u/fQj4I393rYp9sur2HwV05zui+19+U1qSVJp0A8xSZJmiAEhSSoZEJKkkgEhSSoZEJKkkgGhWSsi1k8814Tr+OuIOGc6f39EbIyIu9qdU++OiA9FxC5t2nBEfG4r6xyKiHdsZfpBEXFtGz43Ii6fZM3nRsRBPeNXRcSRk1mHNGrexLNIgyszr5iB1T6Z3W0tiIgD6O4a+hxgSWaOACNbWXYIeEdbZgsRMS8zH2PzF7q2x7l034V4DCAz/3IK69Ic5x6EBkr71vB1EXF7e72itX82Ij7ahk+NiJsjYpeIuDgiLmjtL4iIb7dP/XdExBERsVdErGjjqyNiUncDzsx1wHnA37Rvar+q5xkEJ7c9jbvaswn2Bj4BnNTa/r594l8WEd8BVrQ9jDU9v+L5EfHd6J5XsaStd4t5IuKCtp2LgWFgaVv/nm3Z4Tbf29s2romIy3qWXx8RH2/9cmtEHIiEAaHB81ng05l5HPBW2i2dgYuAt0XEKcDn6L4VvWnMskuBz2fmnwAvp/tm+lPAGZl5DHAK8Ml2K49tlpkP0T2b5IAxky4A3t/2Nk4CnqR7TsX3M/PozPx0m+8YYHFmnlys/vi2nUcBZ46+2Y9Tx7V0ey9nt/U/OTqtHXa6jO7eREcDx0XE6C2vnw3c2vrlZuCvtn3rtTMzIDRoXgtcHt2trZcBz4mIvTLz/+je2JYDl2fmg70LtU/vB2fm1wAy86m2TACXRsQ9dLfnOJjNtwmfqluAT0XEB4B9c/Ptpsdanpljn/XRO+3x9mZ/Pd1tRrbHccB3M/NnrY6ldA+hAvg9cGMbXkV3GEzyHIQGzi7ACZn5VDHtj+nuxHlQMW08ZwMLgWMzc0O7C+gekykoIg4HNtLdPfbFo+2Z+YmI+AbdfaJuifEfW/nEVlY/9l44CfyBLT/cTarewobcfM+djfi+oMY9CA2abwF/OzoSEaMniw8FPkT38KA3RsTLehfK7slzPx49rNLu0vksuts7r2vhcApw6GSKiYiFdI+wvLznTXZ02hGZuTozL6O78/CLgN/SPSZ1W70uumdt70n3FLRbgJ8CB0TEcyNid+DNPfOPt/6VwMkRsSAidgXeDnxvEnVoDvKTgmazZ0XEj3vGPwV8APh8OyQ0D7g5It5Ld/vvCzLzsYh4D3B1RBw3Zn1/AXwhIj5Gd1fcM+kOtXw9IlbTHb+/bxvq2rMd4ppP92n+X1ptY53fQmcT8AO652JvAjZGxN3A1cAvJ/hdK+mee7EIuKZdJUXbhpV0zyjorflq4IqIeJLumRBA95jWiLiQ7rbXAXwjM29A2grv5ipJKnmISZJUMiAkSSUDQpJUMiAkSSUDQpJUMiAkSSUDQpJUMiAkSaX/B+rFhwvUy+5OAAAAAElFTkSuQmCC\n",
            "text/plain": "<Figure size 432x288 with 1 Axes>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Let's see if the `.concordance()` method from `nltk` is available:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Here's a manual way of doing a concordance, tjough we need to clean it for the tokeniser?\nfrom cltk.corpus.utils.formatter import remove_non_ascii\nfrom cltk.corpus.utils.formatter import remove_non_latin\n\naen1_clean = remove_non_ascii(aen1.raw())\naen1_clean = remove_non_latin(aen1_clean)\n#print(aen1_clean[:1000])\n\nfrom cltk.tokenize.word import WordTokenizer\nfrom nltk.text import Text\n\nword_tokenizer = WordTokenizer('latin')\n\ntokens = word_tokenizer.tokenize(aen1_clean)\ntextList = Text(tokens)\ntextList.concordance('Libyae')",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Displaying 7 of 7 matches:\nello -que superbum venturum excidio Libyae sic volvere Parcas Id metuens veter\na litora cursu contendunt petere et Libyae vertuntur ad oras Est in secessu lo\nulos sic vertice caeli constitit et Libyae defixit lumina regnis Atque illum t\ne per aera magnum remigio alarum ac Libyae citus adstitit oris Et iam iussa fa\no -que supersunt Ipse ignotus egens Libyae deserta peragro Europa atque Asia p\ne pater optime Teucrum pontus habet Libyae nec spes iam restat Iuli at freta S\nuidem per litora certos dimittam et Libyae lustrare extrema iubebo si quibus e\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#A better way is to take the tokenised version of the words from the corpus\nText(aen1.words()).concordance('Libyae')",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Displaying 7 of 7 matches:\n belloque superbum venturum excidio Libyae : sic volvere Parcas . Id metuens ,\ntora , cursu contendunt petere , et Libyae vertuntur ad oras . Est in secessu \nic vertice caeli 225 constitit , et Libyae defixit lumina regnis . Atque illum\naera magnum 300 remigio alarum , ac Libyae citus adstitit oris . Et iam iussa \n supersunt . Ipse ignotus , egens , Libyae deserta peragro , Europa atque Asia\nr optime Teucrum , 555 pontus habet Libyae , nec spes iam restat Iuli , at fre\nuidem per litora certos dimittam et Libyae lustrare extrema iubebo , si quibus\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Being able to search a text is really useful."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from cltk.ir.query import match_regex\n\n#Sentence context\nmatches = match_regex(aen1.raw(), r'Libyae', language='latin',\n                      context='sentence', case_insensitive=True)\n\nfor match in matches:\n    print(match,'\\n---\\n')",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\nProgeniem sed enim Troiano a sanguine duci \naudierat, Tyrias olim quae verteret arces;    20 \nhinc populum late regem belloque superbum \nventurum excidio *Libyae*: sic volvere Parcas. \n---\n\n \n\n \nDefessi Aeneadae, quae proxima litora, cursu \ncontendunt petere, et *Libyae* vertuntur ad oras. \n---\n\n \n\n \nEt iam finis erat, cum Iuppiter aethere summo \ndespiciens mare velivolum terrasque iacentis \nlitoraque et latos populos, sic vertice caeli    225 \nconstitit, et *Libyae* defixit lumina regnis. \n---\n\n\n \n\n \nHaec ait, et Maia genitum demittit ab alto, \nut terrae, utque novae pateant Karthaginis arces \nhospitio Teucris, ne fati nescia Dido \nfinibus arceret: volat ille per aera magnum    300 \nremigio alarum, ac *Libyae* citus adstitit oris. \n---\n\n\nIpse ignotus, egens, *Libyae* deserta peragro, \nEuropa atque Asia pulsus. \n---\n\n   550 \nQuassatam ventis liceat subducere classem, \net silvis aptare trabes et stringere remos: \nsi datur Italiam, sociis et rege recepto, \ntendere, ut Italiam laeti Latiumque petamus; \nsin absumpta salus, et te, pater optime Teucrum,    555 \npontus habet *Libyae*, nec spes iam restat Iuli, \nat freta Sicaniae saltem sedesque paratas, \nunde huc advecti, regemque petamus Acesten. \n---\n\nEquidem per litora certos \ndimittam et *Libyae* lustrare extrema iubebo, \nsi quibus eiectus silvis aut urbibus errat. \n---\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#10 characters either way context\nmatches = match_regex(aen1.raw(), r'Libyae', language='latin',\n                      context=10, case_insensitive=True)\n\nfor match in matches:\n    print(match)",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": "m excidio *Libyae*: sic volv\netere, et *Libyae* vertuntur\ntitit, et *Libyae* defixit l\nlarum, ac *Libyae* citus ads\ns, egens, *Libyae* deserta p\ntus habet *Libyae*, nec spes\nmittam et *Libyae* lustrare \n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Named entities\n\nThe named entity recognition is a but ropey, but it's a start?"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from cltk.tag import ner\nfrom cltk.stem.latin.j_v import JVReplacer\n\n\njv_replacer = JVReplacer()\n\ntext_str_iu = jv_replacer.replace(aen1.raw())\n\ntagged = ner.tag_ner('latin', input_text=text_str_iu, output_type=list)",
      "execution_count": 29,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "[w for w,_ in set([w for w in tagged if 'Entity' in w])][:10]",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "text/plain": "['Tyrias',\n 'Regius',\n 'Pariusue',\n 'Tiberinaque',\n 'Seu',\n 'Aiacis',\n 'Notus',\n 'Pergama',\n 'Lucus',\n 'Cymothoe']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Declensions\n\nFind the inflection (declension / conjugation) of a given word / lemma.\n\n(*Lemma* - \"the canonical form of an inflected word\".)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from cltk.stem.latin.declension import CollatinusDecliner\n\nCorpusImporter('latin').import_corpus('latin_models_cltk')",
      "execution_count": 31,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The morphological character of a word is encoded using a nine character code string (- is used as the null character):\n\n \t1: \tpart of speech\n \t\tn\tnoun\n \t\tv\tverb\n \t\tt\tparticiple\n \t\ta\tadjective\n \t\td\tadverb\n \t\tc\tconjunction\n \t\tr\tpreposition\n \t\tp\tpronoun\n \t\tm\tnumeral\n \t\ti\tinterjection\n \t\te\texclamation\n \t\tu\tpunctuation\n \t2: \tperson\n \t\t1\tfirst person\n \t\t2\tsecond person\n \t\t3\tthird person\n \t3: \tnumber\n \t\ts\tsingular\n \t\tp\tplural\n \t4: \ttense\n \t\tp\tpresent\n \t\ti\timperfect\n \t\tr\tperfect\n \t\tl\tpluperfect\n \t\tt\tfuture perfect\n \t\tf\tfuture\n \t5: \tmood\n \t\ti\tindicative\n \t\ts\tsubjunctive\n \t\tn\tinfinitive\n \t\tm\timperative\n \t\tp\tparticiple\n \t\td\tgerund\n \t\tg\tgerundive\n \t\tu\tsupine\n \t6: \tvoice\n \t\ta\tactive\n \t\tp\tpassive\n \t7:\tgender\n \t\tm\tmasculine\n \t\tf\tfeminine\n \t\tn\tneuter\n \t8: \tcase\n \t\tn\tnominative\n \t\tg\tgenitive\n \t\td\tdative\n \t\ta\taccusative\n \t\tb\tablative\n \t\tv\tvocative\n \t\tl\tlocative\n \t9: \tdegree\n \t\tc\tcomparative\n \t\ts\tsuperlative\n \nVia: https://github.com/cltk/latin_treebank_perseus#readme"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "decliner = CollatinusDecliner()\n\ndecliner.decline(\"amo\")[:20]",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 32,
          "data": {
            "text/plain": "[('amo', 'v1spia---'),\n ('amas', 'v2spia---'),\n ('amat', 'v3spia---'),\n ('amamus', 'v1ppia---'),\n ('amatis', 'v2ppia---'),\n ('amant', 'v3ppia---'),\n ('amabam', 'v1siia---'),\n ('amabas', 'v2siia---'),\n ('amabat', 'v3siia---'),\n ('amabamus', 'v1piia---'),\n ('amabatis', 'v2piia---'),\n ('amabant', 'v3piia---'),\n ('amabo', 'v1sfia---'),\n ('amabis', 'v2sfia---'),\n ('amabit', 'v3sfia---'),\n ('amabimus', 'v1pfia---'),\n ('amabitis', 'v2pfia---'),\n ('amabunt', 'v3pfia---'),\n ('amavi', 'v1sria---'),\n ('amavisti', 'v2sria---')]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can decode the strings to more easily describe the morphological character of a word."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Taken from https://github.com/alpheios-project/pyperseus-treebank/blob/master/pyperseus_treebank/latin.py#L44#\n#Maybe use https://github.com/jazzband/inflect for natural language code2text description?\nimport re\n\n# Conversion table for CONLL\n# Thanks to @epageperron\n#??Some divergence from README?\n_CONLL_LA_CONV_DICT = { \"a\": \"adjective\", \"c\": \"conjunction\",\n                        \"d\": \"adverb\", \"e\": \"exclamation\", \"g\": \"PART\",\n                        \"i\": \"interjection\", \"l\": \"DET\",\n                        \"m\": \"numeral\", \"n\": \"noun\",\"p\": \"pronoun\",\n                        \"r\": \"preposition\", \"t\": \"VERB\", \"u\": \"punctuation\",\n                        \"v\": \"verb\", \"x\": \"X\" }\n\n_NUMBER = {\"s\": \"singular\", \"p\": \"plural\"}\n_TENSE = {\"p\": \"present\", \"f\": \"future\", \"r\": \"perfect\", \"l\": \"pluperfect\",\n          \"i\": \"imperfect\", \"t\": \"future perfect\"}\n_MOOD = {\"i\": \"indicative\", \"s\": \"subjunctive\", \"m\": \"imperative\", 'd':'gerund',\n         \"g\": \"gerundive\", \"p\": \"participle\", \"u\": \"supine\", \"n\": \"infinitive\"}\n_VOICE = {\"a\": \"active\", \"p\": \"passive\", \"d\": \"Dep\"}\n_GENDER = {\"f\": \"feminine\", \"m\": \"masculine\", \"n\": \"neuter\", \"c\": \"Com\"}\n_CASE = {\"g\": \"genitive\", \"d\": \"dative\", \"a\": \"accusative\", \"v\": \"vocative\",\n         \"n\": \"nominative\", \"b\": \"ablative\", \"i\": \"Ins\", \"l\": \"locative\"}\n_DEGREE = {\"p\": \"Pos\", \"c\": \"comparative\", \"s\": \"superlative\"}\n\n_PERSON = {\"1\":'first person', \"2\":'second person', \"3\":'third person'}\n\nNOTWORD = re.compile(\"^\\W+$\")\n\n_NULL_CHAR=\"-\"\n\ndef parse_features(features):\n    \"\"\" Parse features from the POSTAG of Perseus Latin XML\n    .. example :: self.parse_features(\"n-p---na-\")\n    :param features: A string containing morphological informations\n    :type features: str\n    :return: Parsed features\n    :rtype: dict\n    \"\"\"\n\n    if features is None or features.lower()=='unk':\n        return {}\n    \n    features = features.lower()\n    \n    feats = {}\n\n    feats['POS'] = _CONLL_LA_CONV_DICT[features[0]]\n\n    # Person handling : 3 possibilities\n    if features[1] != _NULL_CHAR:\n        feats[\"Person\"] = _PERSON[features[1]]\n\n    # Number handling : two possibilities\n    if features[2] != _NULL_CHAR:\n        feats[\"Number\"] = _NUMBER[features[2]]\n\n    # Tense\n    if features[3] != _NULL_CHAR:\n        feats[\"Tense\"] = _TENSE[features[3]]\n\n    # Mood\n    if features[4] != _NULL_CHAR:\n        feats[\"Mood\"] = _MOOD[features[4]]\n\n    # Voice\n    if features[5] != _NULL_CHAR:\n        feats[\"Voice\"] = _VOICE[features[5]]\n\n    # Tense\n    if features[6] != _NULL_CHAR:\n        feats[\"Gender\"] = _GENDER[features[6]]\n\n    # Tense\n    if features[7] != _NULL_CHAR:\n        feats[\"Case\"] = _CASE[features[7]]\n\n    # Degree\n    if features[8] != _NULL_CHAR:\n        feats[\"Degree\"] = _DEGREE[features[8]]\n\n    return feats\n",
      "execution_count": 35,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Example\nparse_features('v3plia---')",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "{'Mood': 'indicative',\n 'Number': 'plural',\n 'POS': 'verb',\n 'Person': 'third person',\n 'Tense': 'pluperfect',\n 'Voice': 'active'}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Looking up words in the decliner provides a way of getting the morphological data for a word. For example, we could look up `amabitis` and get back something like `('amo', 'v2pfia---')` "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#hacky way that assumes you know the root\ndef lookupInflection(word, lemma):\n    ''' Find the inflection of a given word, given its lemma. '''\n    result=[]\n    if lemma is None:\n        return result\n    \n    lemma = [lemma] if isinstance(lemma,str) else lemma\n    for l in lemma:\n        try:\n            words = decliner.decline(l)\n            result.append([(w,d) for w,d in words if w==word])\n        except:\n            result.append((l, None))\n    return result\n\nlookupInflection('amabitis','amo')",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 34,
          "data": {
            "text/plain": "[[('amabitis', 'v2pfia---')]]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Lemmatizer - find root of a word\nfrom cltk.stem.lemma import LemmaReplacer\n\nfrom cltk.stem.latin.j_v import JVReplacer\n\n#Lemmatizer requires the following\nCorpusImporter('latin').import_corpus('latin_pos_lemmata_cltk')\nCorpusImporter('latin').import_corpus('latin_models_cltk')\n\n\nsentence = 'Progeniem sed enim Troiano a sanguine duci audierat'\n\nsentence = sentence.lower()\n\nlemmatizer = LemmaReplacer('latin')\n\nlemmatizer.lemmatize(sentence)",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/plain": "['progenies', 'sed', 'enim', 'troiano', 'ab', 'sanguis', 'duco', 'audio']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "lemmatizer.lemmatize('audierat')",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "['audio']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#We're getting lists back so this may take a bit more hamdling down the line?\ndef lookupLemmaDec(word):\n    ''' Given a word, find its lemma and inflection. '''\n    \n    lemmatizer = LemmaReplacer('latin')\n    try:\n        lemma = lemmatizer.lemmatize(word)\n    except:\n        lemma = None\n    #Maybe work on a better response format?\n    return lemma, lookupInflection(word,lemma)\n\nlookupLemmaDec('amabas')",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 37,
          "data": {
            "text/plain": "(['amo'], [[('amabas', 'v2siia---')]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(lookupLemmaDec('audierat'))\n\n\n#audierat not found when declining audio?\n#so how does lemmatizer work?\nfor word, grammarstring in  decliner.decline(\"audio\"):\n    if word=='audierat': print('got it')",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(['audio'], [[]])\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "cell_type": "markdown",
      "source": "### Parts of Speech (POS) Tagging\n\nCLTK includes several parts of speech (POS) taggers that can be used to parse the morphology of each word in a sentence."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from cltk.stem.latin.declension import CollatinusDecliner\nCorpusImporter('latin').import_corpus('latin_models_cltk')\n\nfrom cltk.tag.pos import POSTag\n\ntagger = POSTag('latin')\n\nsentence = 'Progeniem sed enim Troiano a sanguine duci audierat'\n\ntagger.tag_ngram_123_backoff(sentence)",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": "[('Progeniem', None),\n ('sed', 'C--------'),\n ('enim', 'C--------'),\n ('Troiano', None),\n ('a', 'R--------'),\n ('sanguine', 'N-S---MB-'),\n ('duci', 'V--PNP---'),\n ('audierat', 'V3SLIA---')]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "tagger.tag_tnt(sentence)",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "[('Progeniem', 'Unk'),\n ('sed', 'C--------'),\n ('enim', 'C--------'),\n ('Troiano', 'Unk'),\n ('a', 'R--------'),\n ('sanguine', 'N-S---MB-'),\n ('duci', 'V--PNP---'),\n ('audierat', 'V3SLIA---')]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for w,m in tagger.tag_ngram_123_backoff(sentence):\n    print(w,parse_features(m))",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Progeniem {}\nsed {'POS': 'CCONJ'}\nenim {'POS': 'CCONJ'}\nTroiano {}\na {'POS': 'ADP'}\nsanguine {'POS': 'NOUN', 'Gender': 'Masc', 'Number': 'Sing', 'Case': 'Abl'}\nduci {'POS': 'VERB', 'Voice': 'Pass', 'Mood': 'Inf', 'Tense': 'Pres'}\naudierat {'POS': 'VERB', 'Person': '3', 'Number': 'Sing', 'Voice': 'Act', 'Mood': 'Ind', 'Tense': 'PQP'}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for w,m in tagger.tag_tnt(sentence):\n    print(w,parse_features(m))",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Progeniem {}\nsed {'POS': 'CCONJ'}\nenim {'POS': 'CCONJ'}\nTroiano {}\na {'POS': 'ADP'}\nsanguine {'POS': 'NOUN', 'Gender': 'Masc', 'Number': 'Sing', 'Case': 'Abl'}\nduci {'POS': 'VERB', 'Voice': 'Pass', 'Mood': 'Inf', 'Tense': 'Pres'}\naudierat {'POS': 'VERB', 'Person': '3', 'Number': 'Sing', 'Voice': 'Act', 'Mood': 'Ind', 'Tense': 'PQP'}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "parse_features('V3SLIA---')",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "{'Mood': 'Ind',\n 'Number': 'Sing',\n 'POS': 'VERB',\n 'Person': '3',\n 'Tense': 'PQP',\n 'Voice': 'Act'}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Round trip - large amount of print output\n#lemma='amo'\n#for word, c in decliner.decline(lemma):\n#    print(word, c, lookupLemmaDec(word))",
      "execution_count": 79,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Syllables\n\nOne way of helping students read a text is to split the syllables out."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from cltk.stem.latin.syllabifier import Syllabifier\nsyllabifier = Syllabifier()\n\n\nmatch = list(match_regex(aen1.raw(), r'Libyae', language='latin',\n                      context='sentence', case_insensitive=True))[0].replace('*','')\nprint(match,'\\n')\n\n#Extract syllables for each word\nfor word in word_tokenize(match.lower()):\n    syllables = syllabifier.syllabify(word)\n    print(word, syllables)",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\nProgeniem sed enim Troiano a sanguine duci \naudierat, Tyrias olim quae verteret arces;    20 \nhinc populum late regem belloque superbum \nventurum excidio Libyae: sic volvere Parcas. \n\nprogeniem ['pro', 'ge', 'ni', 'em']\nsed ['sed']\nenim ['e', 'nim']\ntroiano ['tro', 'ia', 'no']\na ['a']\nsanguine ['san', 'gu', 'i', 'ne']\nduci ['du', 'ci']\naudierat ['au', 'di', 'e', 'rat']\n, [',']\ntyrias ['ty', 'ri', 'as']\nolim ['o', 'lim']\nquae ['quae']\nverteret ['ver', 'te', 'ret']\narces ['ar', 'ces']\n; [';']\n20 ['20']\nhinc ['hinc']\npopulum ['po', 'pu', 'lum']\nlate ['la', 'te']\nregem ['re', 'gem']\nbelloque ['bel', 'lo', 'que']\nsuperbum ['su', 'per', 'bum']\nventurum ['ven', 'tu', 'rum']\nexcidio ['ex', 'ci', 'di', 'o']\nlibyae ['li', 'by', 'ae']\n: [':']\nsic ['sic']\nvolvere ['vol', 've', 're']\nparcas ['par', 'cas']\n. ['.']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Let's see if we can put the text back together, but split out the syllables..."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sylltxt_list=[]\nfor word in word_tokenize(match.lower()):\n    #Get the syllables for each word\n    syllables = syllabifier.syllabify(word)\n    #then join them together with hyphens\n    sylltxt_list.append('-'.join(syllables))\n\n#Now put the syllabified wordlist back together as a single string\ntxt = ' '.join(sylltxt_list)\n               \nprint(match,'\\n\\n',txt)",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\nProgeniem sed enim Troiano a sanguine duci \naudierat, Tyrias olim quae verteret arces;    20 \nhinc populum late regem belloque superbum \nventurum excidio Libyae: sic volvere Parcas. \n\n pro-ge-ni-em sed e-nim tro-ia-no a san-gu-i-ne du-ci au-di-e-rat , ty-ri-as o-lim quae ver-te-ret ar-ces ; 20 hinc po-pu-lum la-te re-gem bel-lo-que su-per-bum ven-tu-rum ex-ci-di-o li-by-ae : sic vol-ve-re par-cas .\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Comparing word counts\n\nAn activity in the *OpenLearn* unit [Discovering Ancient Greek and Latin](http://www.open.edu/openlearn/history-the-arts/discovering-ancient-greek-and-latin/content-section-7.1) compares word counts in parallel English and Ancient Greek texts.\n\nIt is simple to run a count on words in a text.\n\n>__Euripides, Bacchae, 1.1−3.__\n>The god Dionysus (Bacchus) announces his arrival at the Greek city of Thebes.\n>\n>__English__\n>\n>*I, son of Zeus, have reached this land of Thebans, Dionysos, whom the daughter of Kadmos, Semele, once bore, brought to labour by lightning-bearing flame.*\n>\n>__Greek__\n>\n>ἥκω Διὸς παῖς τήνδε Θηβαίων χθόνα\n>\n>Διόνυσος, ὃν τίκτει ποθ᾽ ἡ Κάδμου κόρη\n>\n>Σεμέλη λοχευθεῖσ᾽ ἀστραπηφόρῳ πυρί\n>\n>__transliteration__\n>\n>hēkō Dios pais tēnde Thēbaiōn chthona\n>\n>Dionysos, hon tiktei poth' hē Kadmou korē\n>\n>Semelē locheutheis' astrapēphorōi pyri\n\n\nBy the by, I note Google Translate's version: *\"Behold the Divine tones, Dionysus, the daughter of Kadmos, Horns are loaded with fire-retardant fire*."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The Greek tokeniser requires us to load the `greek_models_cltk` corpus first:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from cltk.corpus.utils.importer import CorpusImporter\n\nCorpusImporter('greek').import_corpus('greek_models_cltk')",
      "execution_count": 57,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Count English tokens\n\ntxt = '''I, son of Zeus, have reached this land of Thebans, Dionysos, whom the daughter of Kadmos, Semele, once bore, brought to labour by lightning-bearing flame.'''\n\nprint(txt.split(), len(txt.split()))",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['I,', 'son', 'of', 'Zeus,', 'have', 'reached', 'this', 'land', 'of', 'Thebans,', 'Dionysos,', 'whom', 'the', 'daughter', 'of', 'Kadmos,', 'Semele,', 'once', 'bore,', 'brought', 'to', 'labour', 'by', 'lightning-bearing', 'flame.'] 25\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Applying an nltk English tokeniser naively as the basis of a wordcount goes wrong\n# because we split out punctaution characters as separate tokens.\nimport nltk\n\nprint(nltk.word_tokenize(txt), len(nltk.word_tokenize(txt)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#A fix is to create a function that returns a punctuation stripped token list:\nimport string\n\nprint(\"Ignore these:\",string.punctuation,'\\n')\n\ndef noPuncTokens(tokens):\n    return [token for token in tokens if token not in string.punctuation]\n            \nprint(noPuncTokens(nltk.word_tokenize(txt)), len(noPuncTokens(nltk.word_tokenize(txt))))   ",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Ignore these: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \n\n['I', 'son', 'of', 'Zeus', 'have', 'reached', 'this', 'land', 'of', 'Thebans', 'Dionysos', 'whom', 'the', 'daughter', 'of', 'Kadmos', 'Semele', 'once', 'bore', 'brought', 'to', 'labour', 'by', 'lightning-bearing', 'flame'] 25\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from cltk.tokenize.word import WordTokenizer\n\ngk='''ἥκω Διὸς παῖς τήνδε Θηβαίων χθόνα\n\nΔιόνυσος, ὃν τίκτει ποθ᾽ ἡ Κάδμου κόρη\n\nΣεμέλη λοχευθεῖσ᾽ ἀστραπηφόρῳ πυρί'''\nprint(gk,'\\n')\n\ngreek_word_tokenizer = WordTokenizer('greek')\n\n#This suffers same problem as naive nltk tokeniser - punctuation is split out too\nprint('Greek tokeniser:',greek_word_tokenizer.tokenize(gk), '\\n')\n\n#So strip...\ngkNoPuncTokens=noPuncTokens(greek_word_tokenizer.tokenize(gk))\nprint('Depunctuate....:',gkNoPuncTokens, len(gkNoPuncTokens))",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": "ἥκω Διὸς παῖς τήνδε Θηβαίων χθόνα\n\nΔιόνυσος, ὃν τίκτει ποθ᾽ ἡ Κάδμου κόρη\n\nΣεμέλη λοχευθεῖσ᾽ ἀστραπηφόρῳ πυρί \n\nGreek tokeniser: ['ἥκω', 'Διὸς', 'παῖς', 'τήνδε', 'Θηβαίων', 'χθόνα', 'Διόνυσος', ',', 'ὃν', 'τίκτει', 'ποθ᾽', 'ἡ', 'Κάδμου', 'κόρη', 'Σεμέλη', 'λοχευθεῖσ᾽', 'ἀστραπηφόρῳ', 'πυρί'] \n\nDepunctuate....: ['ἥκω', 'Διὸς', 'παῖς', 'τήνδε', 'Θηβαίων', 'χθόνα', 'Διόνυσος', 'ὃν', 'τίκτει', 'ποθ᾽', 'ἡ', 'Κάδμου', 'κόρη', 'Σεμέλη', 'λοχευθεῖσ᾽', 'ἀστραπηφόρῳ', 'πυρί'] 17\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Pronunciation and Transliteration\n\nHow to pronounce Latin words may be something students struggle with. A text to speech generator would be useful, but that would presumably have to be trained for use on Latin pronunciations.\n\nAn OU guide to Latin pronunciation can be found here: http://www.open.ac.uk/Arts/introducing-classical-latin/ .\n\nLong Latin vowels can be automatically marked with a macron."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from cltk.prosody.latin.macronizer import Macronizer\n\nmacronizer = Macronizer('tag_ngram_123_backoff')\n\ntext = 'Quo usque tandem, O Catilina, abutere nostra patientia?'\n\nmacronizer.macronize_text(text)",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 44,
          "data": {
            "text/plain": "'quō usque tandem , ō catilīnā , abūtēre nostrā patientia ?'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "match = list(match_regex(aen1.raw(), r'Libyae', language='latin',\n                      context='sentence', case_insensitive=True))[0].replace('*','')\nprint(macronizer.macronize_text(match))",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": "progeniem sed enim troiano ā sanguine dūcī audierat , tyrias ōlim quae verteret arcēs ; 20 hinc populum lātē rēgem belloque superbum ventūrum excidio libyae : sīc volvere parcas .\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#We can combine the macronised text with the syllabifier\nsylltxt_list=[]\nfor word in word_tokenize(macronizer.macronize_text(match).lower()):\n    #Get the syllables for each word\n    syllables = syllabifier.syllabify(word)\n    #then join them together with hyphens\n    sylltxt_list.append('-'.join(syllables))\n\n#Now put the syllabified wordlist back together as a single string\ntxt = ' '.join(sylltxt_list)\n               \nprint(match,'\\n\\n',txt)",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\nProgeniem sed enim Troiano a sanguine duci \naudierat, Tyrias olim quae verteret arces;    20 \nhinc populum late regem belloque superbum \nventurum excidio *Libyae*: sic volvere Parcas. \n\n pro-ge-ni-em sed e-nim tro-ia-no ā san-gu-i-ne dū-cī au-di-e-rat , ty-ri-as ō-lim quae ver-te-ret ar-cēs ; 20 hinc po-pu-lum lā-tē rē-gem bel-lo-que su-per-bum ven-tū-rum ex-ci-di-o * li-by-ae * : sīc vol-ve-re par-cas .\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Another approach is to require students to learn how to read and pronounce something like the IPA phonetic transliteration alphabet."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%capture\ntry:\n    import greek_accentuation\nexcept:\n    !pip install greek_accentuation",
      "execution_count": 66,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from cltk.phonology.latin.transcription import Transcriber\n\ntranscriber = Transcriber(dialect=\"Classical\", reconstruction=\"Allen\")\n\nmatch = list(match_regex(aen1.raw(), r'Libyae', language='latin',\n                      context='sentence', case_insensitive=True))[0]\n\nprint(match)\n\nt=remove_non_ascii(match)\nt=remove_non_latin(t)\ntranscriber.transcribe(t)",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\nProgeniem sed enim Troiano a sanguine duci \naudierat, Tyrias olim quae verteret arces;    20 \nhinc populum late regem belloque superbum \nventurum excidio *Libyae*: sic volvere Parcas.\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 71,
          "data": {
            "text/plain": "\"[prɔ.'gɛ.n̪ɪ̣.jẽː 'sɛd̪ 'ɛn̪ĩː 't̪rɔj.ja.n̪ɔ 'aː 'saŋ.gʷɪ.n̪ɛ 'd̪uː.kiː aw.'d̪ɪ̣.jɛ.rat̪ 't̪y.rɪ̣.jas 'oːɫĩː 'kʷaj 'wɛr.t̪ɛ.rɛt̪ 'ar.keːs 'hɪŋk 'pɔ.pʊ.ɫũː 'laː.t̪eː 'reː.gẽː 'bɛɫ.lɔ.kʷɛ sʊ.'pɛr.bũː wɛn̪.'t̪uː.rũː ɛks.'kɪ.d̪ɪ̣.jɔ 'lɪ.by.jaj 'siːk 'wɔɫ.wɛ.rɛ 'par.kas]\""
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "I'm guessing this would be really useful for languages with non-Roman alphabets, although it does run the risk of replacing one form of Greek with another (?!), and may also make it harder to learn the sounds associated with the actual characters in the target language?"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from cltk.phonology.greek.transcription import Transcriber\n\ntranscriber = Transcriber(dialect=\"Attic\", reconstruction=\"Probert\")\n\nt=\"Διόθεν καὶ δισκήπτρου τιμῆς ὀχυρὸν ζεῦγος Ἀτρειδᾶν στόλον Ἀργείων\"\n\nprint(t)\ntranscriber.transcribe(t)",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Διόθεν καὶ δισκήπτρου τιμῆς ὀχυρὸν ζεῦγος Ἀτρειδᾶν στόλον Ἀργείων\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 72,
          "data": {
            "text/plain": "'[di.ó.tʰen kɑj dis.kɛ́ːp.trọː ti.mɛ̂ːs o.kʰy.ron zdêw.gos ɑ.trẹː.dɑ̂n stó.lon ɑr.gẹ́ː.ɔːn]'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "t='''ἥκω Διὸς παῖς τήνδε Θηβαίων χθόνα\n\nΔιόνυσος, ὃν τίκτει ποθ᾽ ἡ Κάδμου κόρη\n\nΣεμέλη λοχευθεῖσ᾽ ἀστραπηφόρῳ πυρί'''\ntranscriber.transcribe(t)",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 73,
          "data": {
            "text/plain": "'[hɛ́ː.kɔː di.os pɑ̂js tɛ́ːn.de tʰɛː.bɑ́.jɔːn kʰtʰó.nɑ di.ó.ny.sos hon tík.tẹː potʰ hɛː kɑ́d.mọː kó.rɛː se.mé.lɛː lo.kʰew.tʰệːs ɑs.trɑ.pɛː.pʰó.rɔːj py.rí]'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Note that OpenLearn materials use a different transliteration alphabet?\n\n>hēkō Dios pais tēnde Thēbaiōn chthona\n>Dionysos, hon tiktei poth' hē Kadmou korē\n>Semelē locheutheis' astrapēphorōi pyri"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from cltk.phonology.arabic.romanization import transliterate\n\nmode = 'buckwalter'\nar_string = 'بِسْمِ اللهِ الرَّحْمٰنِ الرَّحِيْمِ' # translate in English: In the name of Allah, the Most Merciful, the Most Compassionate\nignore = '' # this is for ignore an arabic char from transliterate operation\nreverse = True # true means transliteration from arabic native script to roman script such as Buckwalter\n\nprint(ar_string)\ntransliterate(mode, ar_string, ignore, reverse)",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": "بِسْمِ اللهِ الرَّحْمٰنِ الرَّحِيْمِ\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 74,
          "data": {
            "text/plain": "'bisomi Allhi Alra~Hom`ni Alra~Hiyomi'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from cltk.corpus.sanskrit.itrans.unicode_transliterate import ItransTransliterator\n\nsanskrit_text=u'राजस्थान'\n\nlang='hi'\n\nprint(sanskrit_text)\nItransTransliterator.to_itrans(sanskrit_text,lang)",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": "राजस्थान\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 75,
          "data": {
            "text/plain": "'rAjasthAna'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from cltk.phonology.old_english.phonology import Transliterate as t\n\nanglo_saxon_runes = 'ᚩᚠᛏ ᛋᚳᚣᛚᛞ ᛋᚳᛖᚠᛁᛝ ᛋᚳᛠᚦᛖᚾᚪ ᚦᚱᛠᛏᚢᛗ'\n\nprint(anglo_saxon_runes)\nt.transliterate('Latin',anglo_saxon_runes)",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": "ᚩᚠᛏ ᛋᚳᚣᛚᛞ ᛋᚳᛖᚠᛁᛝ ᛋᚳᛠᚦᛖᚾᚪ ᚦᚱᛠᛏᚢᛗ\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 76,
          "data": {
            "text/plain": "'oft scyld scefin sceathena threatum'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Useful Notebooks?\n\nhttps://diyclassics.github.io/notebooks/"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## APIs\n\nNeed a py API wrapper for this? http://data.archaeologydataservice.ac.uk/page/"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#https://pleiades.stoa.org/\n#https://github.com/pelagios/pelagios-cookbook/wiki\n#English Heritage data/shaprfiles https://historicengland.org.uk/listing/the-list/data-downloads/\n#https://electricarchaeology.ca/2018/08/21/jupyter-notebooks-for-digital-archaeology-and-history-too/",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}